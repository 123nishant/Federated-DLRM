{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:18.535547Z",
     "iopub.status.busy": "2020-11-22T15:08:18.534460Z",
     "iopub.status.idle": "2020-11-22T15:08:18.539080Z",
     "shell.execute_reply": "2020-11-22T15:08:18.538446Z"
    },
    "papermill": {
     "duration": 0.025789,
     "end_time": "2020-11-22T15:08:18.539229",
     "exception": false,
     "start_time": "2020-11-22T15:08:18.513440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/criteo-display-ad-challenge/random_submission.zip\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011612,
     "end_time": "2020-11-22T15:08:18.563982",
     "exception": false,
     "start_time": "2020-11-22T15:08:18.552370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **NECESSARY IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:18.597814Z",
     "iopub.status.busy": "2020-11-22T15:08:18.596891Z",
     "iopub.status.idle": "2020-11-22T15:08:20.608123Z",
     "shell.execute_reply": "2020-11-22T15:08:20.607428Z"
    },
    "papermill": {
     "duration": 2.032151,
     "end_time": "2020-11-22T15:08:20.608273",
     "exception": false,
     "start_time": "2020-11-22T15:08:18.576122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# miscellaneous\n",
    "import builtins\n",
    "import functools\n",
    "# import bisect\n",
    "# import shutil\n",
    "import time\n",
    "import json\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# onnx\n",
    "# The onnx import causes deprecation warnings every time workers\n",
    "# are spawned during testing. So, we filter out those warnings.\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import onnx\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel.parallel_apply import parallel_apply\n",
    "from torch.nn.parallel.replicate import replicate\n",
    "from torch.nn.parallel.scatter_gather import gather, scatter\n",
    "import sklearn.metrics\n",
    "\n",
    "# from torchviz import make_dot\n",
    "# import torch.nn.functional as Functional\n",
    "# from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011959,
     "end_time": "2020-11-22T15:08:20.633462",
     "exception": false,
     "start_time": "2020-11-22T15:08:20.621503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##**Data Generation** : \n",
    "import dlrm_data_pytorch as dp\n",
    "\n",
    "Trying to declare it here\n",
    "\n",
    "#**Declaring Embedding Functions**:\n",
    "\n",
    "\n",
    "**quotient-remainder trick**\n",
    "from tricks.qr_embedding_bag import QREmbeddingBag\n",
    "**mixed-dimension trick**\n",
    "from tricks.md_embedding_bag import PrEmbeddingBag, md_solver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011976,
     "end_time": "2020-11-22T15:08:20.657597",
     "exception": false,
     "start_time": "2020-11-22T15:08:20.645621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PrEmbeddingBag** : Mixed Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:20.702057Z",
     "iopub.status.busy": "2020-11-22T15:08:20.700804Z",
     "iopub.status.idle": "2020-11-22T15:08:20.705008Z",
     "shell.execute_reply": "2020-11-22T15:08:20.705503Z"
    },
    "papermill": {
     "duration": 0.035833,
     "end_time": "2020-11-22T15:08:20.705655",
     "exception": false,
     "start_time": "2020-11-22T15:08:20.669822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-95d81fad0afe>, line 90)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-95d81fad0afe>\"\u001b[0;36m, line \u001b[0;32m90\u001b[0m\n\u001b[0;31m    elif embedding_dim = base_dim:\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def md_solver(n, alpha, d0 = None, B = None, round_dim = True, k = None):\n",
    "\n",
    "  \"\"\"\n",
    "  An external facing function call for mixed-dimension assignment with the \n",
    "  alpha power temperature heuristic\n",
    "\n",
    "  Inputs : \n",
    "  n           (torch.LongTensor): Vector of num of rows for each embedding matrix\n",
    "  alpha       (torch.FloatTensor) : Scalar, non-negative, controls dim, skew\n",
    "  d0          (torch.FloatTensor) : Scalar, baseline embedding dimension\n",
    "  B           (torch.FloatTensor) : Scalar, parameter budget for embedding layer\n",
    "  round_dim   (bool) : Flag for rounding dims to nearest pow of 2\n",
    "  k           (torch.LongTensor): Vector of average number of queries per inference\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "  n, indices = torch.sort(n)\n",
    "  k = k[indices] if k is not None else torch.ones(len(n))\n",
    "  d = alpha_power_rule(n.type(torch.float) / k, alpha, d0=d0, B = B)\n",
    "\n",
    "  if round_dim:\n",
    "    d = pow_2_round(d)\n",
    "\n",
    "  undo_sort = [0] * len(indices)\n",
    "  \n",
    "  for i, v in enumerate(indices):\n",
    "    undo_sort[v] = i\n",
    "\n",
    "  return d[undo_sort]\n",
    "\n",
    "def alpha_power_rule(n, alpha, d0 = None, B=None):\n",
    "\n",
    "  if d0 is not None: \n",
    "    lamb = d0 * ( n[0].type(torch.float) ** alpha)\n",
    "\n",
    "  elif B is not None:\n",
    "    lamb = B / torch.sum(n.type(torch.float) ** (1 - alpha))\n",
    "\n",
    "  else : \n",
    "    raise ValueError(\"Must specify either d0 or B\")\n",
    "\n",
    "  d = torch.ones(len(n)) * lamb * (n.type(torch.float) ** (-alpha))\n",
    "\n",
    "  for i in range(len(d)):\n",
    "\n",
    "    if i == 0 and d0 is not None:\n",
    "      d[i] = d0\n",
    "\n",
    "    else : \n",
    "      d[i] = 1 if d[i] <1 else d[i]\n",
    "\n",
    "  return (torch.round(d).type(torch.long))\n",
    "\n",
    "def pow_2_round(dims):\n",
    "\n",
    "  return 2 ** torch.round(torch.log2(dims.type(torch.float)))\n",
    "\n",
    "\n",
    "class PrEmbeddingBag(nn.Module):\n",
    "\n",
    "  # torch.nn.Module : Base class for all neural network modules\n",
    "  # Our model should  subclass this class. \n",
    "  # Can contain other Modules, allowing to nest them in a tree structure. \n",
    "  # We can assign submodules as regular attributes\n",
    "  # Submodules assigned this way will be registered , and will have their parameters converted too \n",
    "  # when you call 'to()'\n",
    "\n",
    "  def __init__(self, num_embeddings, embedding_dim, base_dim):\n",
    "\n",
    "    super(PrEmbeddingBag, self).__init__()\n",
    "    self.embs = nn.EmbeddingBag(\n",
    "        num_embeddings, embedding_dim, mode = \"sum\", sparse = True\n",
    "    )\n",
    "\n",
    "    # super() function is used to give access to methods and properties of a parent or \n",
    "    # sibling class. \n",
    "    # super() function returns an object that represents the parent class.\n",
    "\n",
    "    torch.nn.init.xavier.uniform(self.embs.weight)\n",
    "\n",
    "    if embedding_dim < base_dim:\n",
    "      self.proj = nn.Linear(embedding_dim, base_dim, bias = False)\n",
    "      torch.nn.init.xavier_uniform_(self.proj.weight)\n",
    "    \n",
    "    elif embedding_dim = base_dim:\n",
    "      self.proj = nn.Identity() # Placeholder operator that is Argument-Insensitive\n",
    "\n",
    "    else : \n",
    "      raise ValueError(\n",
    "          \"Embedding dim\" + str(embedding_dim) + \"> base dim\" + str(base_dim)\n",
    "      )\n",
    "\n",
    "  def forward(self, input, offsets=None, per_sample_weights = None):\n",
    "    return self.proj(self.embs(\n",
    "        input, \n",
    "        offsets = offsets,\n",
    "        per_sample_weights = per_sample_weights\n",
    "    ))\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012397,
     "end_time": "2020-11-22T15:08:20.730910",
     "exception": false,
     "start_time": "2020-11-22T15:08:20.718513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Quotient Remainder Embedding Trick**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:20.854726Z",
     "iopub.status.busy": "2020-11-22T15:08:20.849497Z",
     "iopub.status.idle": "2020-11-22T15:08:20.861870Z",
     "shell.execute_reply": "2020-11-22T15:08:20.861199Z"
    },
    "papermill": {
     "duration": 0.118324,
     "end_time": "2020-11-22T15:08:20.861988",
     "exception": false,
     "start_time": "2020-11-22T15:08:20.743664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-a6b2e39f286e>, line 85)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-a6b2e39f286e>\"\u001b[0;36m, line \u001b[0;32m85\u001b[0m\n\u001b[0;31m    __constants__ = ['num_categories', 'embedding_dim', 'num_collisions',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "\n",
    "class QREmbeddingBag(nn.Module):\n",
    "\n",
    "  r\"\"\"Computes sum or mean over 2 'bags' of embeddings, one using the quotient of the indices and the\n",
    "      other using the remainder of the indices, without instantiating the intermediate embeddings, then \n",
    "      performs an operation to combine these.\n",
    "\n",
    "      For bags of constant length and no :attr: 'per_sample_weights', this class\n",
    "\n",
    "      * with ''mode=\"sum\"'' is equivalent to :class:'-torch.nn.Embedding' followed by ''torch.sum(dim=0)'',\n",
    "      * with ''mode=\"mean\"'' is equivalent to :class:'-torch.nn.Embedding' followed by ''torch.sum(dim=0)'',\n",
    "      * with ''mode=\"max\"'' is equivalent to :class:'-torch.nn.Embedding' followed by ''torch.sum(dim=0)''\n",
    "\n",
    "      However, :class:'-torch.nn.EmbeddingBag is much more time and memory efficient than using a chain of \n",
    "      these operations. \n",
    "\n",
    "      QREmbeddingBag also supports per-sample weights as an argument to the forward pass. \n",
    "      This scales the output of the Embedding before performing a weighted reduction as specified \n",
    "      by ''mode''. If :attr: 'per_sample_weights'' is passed, the only supported ''mode'' is \n",
    "      ''sum'', which computes a weighted sum according to :attr:'per_sample_weights.\n",
    "\n",
    "      KNOWN ISSUES: \n",
    "      Autograd breaks with multiple GPUs. It breaks only with multiple embeddings. \n",
    "\n",
    "      Args :\n",
    "\n",
    "        num_categories (int) : total number of unique categories. The input indices must be in 0, 1,...\n",
    "                               ,num_categories - 1.\n",
    "        embedding_dim (list) : list of sizes for each embedding vector in each table. If ''add''\n",
    "                               or ''mult'' operation are used, these embedding dimensions must be the same. \n",
    "                               If a single embedding_dim is used, then it will use this embedding_dim \n",
    "                               for both embedding tables. \n",
    "\n",
    "        num_collisions (int) : number of collisions to enforce.\n",
    "\n",
    "        operation (string, optional): \"concat\", \"add\", or \"mult\" . Specifies the operation to compose embeddings\n",
    "                                      , \"concat\" concatenates embeddings, \"add\" sums the embeddings, and\n",
    "                                      \"mult\" multiplies (component-wise) the embeddings.\n",
    "                                      Default : 'mult'\n",
    "\n",
    "       max_norm (float, optional) : If given, each embedding vector with norm larger than :attr: \n",
    "                                    max_norm is renormalized to have norm :attr: 'max_norm'\n",
    "        norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
    "        scale_grad_by_freq (boolean, optional): if given, this will scale gradients by the inverse of frequency of\n",
    "                                                the words in the mini-batch. Default ``False``.\n",
    "                                                Note: this option is not supported when ``mode=\"max\"``.\n",
    "        mode (string, optional): ``\"sum\"``, ``\"mean\"`` or ``\"max\"``. Specifies the way to reduce the bag.\n",
    "                                 ``\"sum\"`` computes the weighted sum, taking :attr:`per_sample_weights`\n",
    "                                 into consideration. ``\"mean\"`` computes the average of the values\n",
    "                                 in the bag, ``\"max\"`` computes the max value over each bag.\n",
    "                                 Default: ``\"mean\"``\n",
    "        sparse (bool, optional): if ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor. See\n",
    "                                 Notes for more details regarding sparse gradients. Note: this option is not\n",
    "                                 supported when ``mode=\"max\"``.\n",
    "    Attributes:\n",
    "        weight (Tensor): the learnable weights of each embedding table is the module of shape\n",
    "                         `(num_embeddings, embedding_dim)` initialized using a uniform distribution\n",
    "                         with sqrt(1 / num_categories).\n",
    "    Inputs: :attr:`input` (LongTensor), :attr:`offsets` (LongTensor, optional), and\n",
    "        :attr:`per_index_weights` (Tensor, optional)\n",
    "        - If :attr:`input` is 2D of shape `(B, N)`,\n",
    "          it will be treated as ``B`` bags (sequences) each of fixed length ``N``, and\n",
    "          this will return ``B`` values aggregated in a way depending on the :attr:`mode`.\n",
    "          :attr:`offsets` is ignored and required to be ``None`` in this case.\n",
    "        - If :attr:`input` is 1D of shape `(N)`,\n",
    "          it will be treated as a concatenation of multiple bags (sequences).\n",
    "          :attr:`offsets` is required to be a 1D tensor containing the\n",
    "          starting index positions of each bag in :attr:`input`. Therefore,\n",
    "          for :attr:`offsets` of shape `(B)`, :attr:`input` will be viewed as\n",
    "          having ``B`` bags. Empty bags (i.e., having 0-length) will have\n",
    "          returned vectors filled by zeros.\n",
    "        per_sample_weights (Tensor, optional): a tensor of float / double weights, or None\n",
    "            to indicate all weights should be taken to be ``1``. If specified, :attr:`per_sample_weights`\n",
    "            must have exactly the same shape as input and is treated as having the same\n",
    "            :attr:`offsets`, if those are not ``None``. Only supported for ``mode='sum'``.\n",
    "    Output shape: `(B, embedding_dim)`\n",
    "    \"\"\"\n",
    "\n",
    "    __constants__ = ['num_categories', 'embedding_dim', 'num_collisions',\n",
    "                     'operation', 'max_norm', 'norm_type','scale_grad_by_freq',\n",
    "                     'mode','sparse']\n",
    "\n",
    "    \n",
    "    def __init__(self, num_categories, embedding_dim, num_collisions,\n",
    "                 operation='mult', max_norm=None, norm_type=2.,\n",
    "                 scale_grad_by_freq=False, mode='mean', sparse=False,\n",
    "                 _weight=None):\n",
    "      super(QREmbeddingBag, self).__init__()\n",
    "\n",
    "      assert operation in ['concat', 'mult', 'add'], 'Not valid operation!'\n",
    "\n",
    "      self.num_categories = num_categories\n",
    "      \n",
    "      if isinstance(embedding_dim, int) or len(embedding_dim) == 1:\n",
    "        self.embedding_dim = [embedding_dim, embedding_dim]\n",
    "\n",
    "      else:\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "      self.num_collisions = num_collisions\n",
    "      self.operation = operation\n",
    "      self.max_norm = max_norm\n",
    "      self.norm_type = norm_type\n",
    "      self.scale_grad_by_freq = scale_grad_by_freq\n",
    "\n",
    "      if self.operation == 'add' or self.operation == 'mult':\n",
    "\n",
    "        assert self.embedding_dim[0] == self.embedding_dim[1], \\\n",
    "        'Embedding Dimensions do not match'\n",
    "\n",
    "      self.num_embeddings = [int(np.cell(num_categories / num_collisions)),\n",
    "                             num_collisions]\n",
    "\n",
    "      if _weight is None:\n",
    "\n",
    "        self.weight_q = Parameter(torch.Tensor(self.num_embeddings[0], self.embedding_dim[0]))\n",
    "        self.weight_r = Parameter(torch.Tensor(self.num_embeddings[1], self.embedding_dim[1]))\n",
    "        self.reset_parameters()\n",
    "\n",
    "      else : \n",
    "        assert list(_weight[0].shape) == [self.num_embeddings[0], self.embedding_dim[0]], \\\n",
    "        'Shape of weight for quotient table does not match num_embeddings and embedding_dim'\n",
    "\n",
    "        assert list(_weight[1].shape) == (self.num_embeddings[1], self.embedding_dim[1]), \\\n",
    "        'Shape of weight for remainder table does not match num_embeddings and embedding_dim'\n",
    "\n",
    "        self.weight_q = Parameter(_weight[0])\n",
    "        self.weight_r = Parameter(_weight[1])\n",
    "\n",
    "      self.mode = mode\n",
    "      self.sparse = sparse\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "\n",
    "      nn.init.uniform_(self.weight_q_, np.sqrt(1 / self.num_categories))\n",
    "      nn.init.uniform (self.weight_r, np.sqrt(1 / self.num_categories))\n",
    "\n",
    "\n",
    "    def forward(self. input, offsets = None, per_sample_weights = None):\n",
    "\n",
    "      input_q = (input / self,num_collisions).long()\n",
    "      input_r = torch.remainder(input, self.num_collisions).long()\n",
    "\n",
    "      embed_q = F.embedding_bag(input_q, self.weight_q, offsets, self.max_norm,\n",
    "                                self.norm_type, self.scale_grad_by_freq, self.mode,\n",
    "                                self.sparse, per_sample_weights)\n",
    "      embed_r = F.embedding_bag(input_r, self.weight_r, offsets, sekf.max_norm,\n",
    "                                self.norm_type, self.scale_grad_by_freq, self.model,\n",
    "                                self.sparse, per_sample_weights)\n",
    "\n",
    "      if self.operation == 'concat':\n",
    "        embed = torch.cat((embed_q, embed_r), dim=1)\n",
    "\n",
    "      elif self.operation == 'add':\n",
    "        embed = embed_q + embed_r\n",
    "\n",
    "      elif self.operation == 'mult':\n",
    "        embed = embed_q * embed_r\n",
    "\n",
    "      return embed\n",
    "\n",
    "\n",
    "    def extra_repr(self):\n",
    "\n",
    "      s = '{num_embeddings}, {embedding_dim}'\n",
    "\n",
    "      if self.max_norm is not None:\n",
    "        s += ',max_norm = {max_norm}'\n",
    "\n",
    "      if self.norm_type != 2:\n",
    "        s += ', norm_type = {norm_type}'\n",
    "\n",
    "      if self.scale_grad_by_freq is not False:\n",
    "        s += ',scale_grad_by_freq = {scale_grade_by_freq}'\n",
    "\n",
    "      s += ', mode={mode}'\n",
    "      return s.format(**self.__dict__)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012787,
     "end_time": "2020-11-22T15:08:20.888155",
     "exception": false,
     "start_time": "2020-11-22T15:08:20.875368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # # **CREATING EMBEDDING FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:20.923121Z",
     "iopub.status.busy": "2020-11-22T15:08:20.917941Z",
     "iopub.status.idle": "2020-11-22T15:08:20.929268Z",
     "shell.execute_reply": "2020-11-22T15:08:20.928490Z"
    },
    "papermill": {
     "duration": 0.028086,
     "end_time": "2020-11-22T15:08:20.929393",
     "exception": false,
     "start_time": "2020-11-22T15:08:20.901307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m49\u001b[0m\n\u001b[0;31m    return emb_l\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def create_emb (self, m, ln):\n",
    "    \n",
    "    emb_l = nn.ModuleList()\n",
    "    for i in range(0, ln.size):\n",
    "        n = ln[i]\n",
    "        \n",
    "        # Construct Embedding Operator\n",
    "        \n",
    "        if self.qr_flag and n > self.qr_threshold:\n",
    "            # Using Quotient-Remainder Embedding\n",
    "            EE = QREmbeddingBag(n, m, self.qr_collisions,\n",
    "                               operation = self.qr_operation, mode = \"sum\", sparse = True)\n",
    "            \n",
    "            \n",
    "        elif self.md_flag:\n",
    "            # Using Mixed Dimension Embedding\n",
    "            base = max(m)\n",
    "            _m = m[i] if n > self.md_threshold else base\n",
    "            EE = PrEmbeddingBag(n, _m, base)\n",
    "            # use np initialization as below for consistency...\n",
    "            W = np.random.uniform(\n",
    "                            low = -np.sqrt(1/n), high = np.sqrt(1/n), size = (n, _m)\n",
    "            ).astype(np.float32)\n",
    "            \n",
    "            EE.embs.weight.data = torch.tensor(W, requires_grad = True)\n",
    "            \n",
    "        else:\n",
    "            # Using Normal Embedding\n",
    "            '''\n",
    "            Computes sum or mean of bag of embeddings, without instantiating the intermediate embeddings\n",
    "            EmbeddingBag is much more time and memory efficient that using a chain of these operations\n",
    "            '''\n",
    "            EE = nn.EmbeddingBag(n, m, mode = \"sum\", sparse = True)\n",
    "            \n",
    "            # Initialize Embeddings via XAVIER INITIALIZATION\n",
    "            # nn.init.uniform_(EE.weight, a = -np.sqrt(1/n), b = np.sqrt(1/n))\n",
    "            W = np.random.uniform(\n",
    "                        low=-np.sqrt(1 / n), high=np.sqrt(1 / n), size=(n, m)\n",
    "                                ).astype(np.float32)\n",
    "            # approach 1\n",
    "            EE.weight.data = torch.tensor(W, requires_grad=True)\n",
    "            # approach 2\n",
    "            # EE.weight.data.copy_(torch.tensor(W))\n",
    "            # approach 3\n",
    "            # EE.weight = Parameter(torch.tensor(W),requires_grad=True)\n",
    "\n",
    "        emb_l.append(EE)\n",
    "\n",
    "      return emb_l\n",
    "\n",
    "\n",
    "def apply_emb(self, lS_o, lS_i, emb_l):\n",
    "    \n",
    "    \n",
    "    # emb_l : Returned by create_emb\n",
    "    \n",
    "    # WARNING : Notice that we are processing batch at once\n",
    "    # We implicitly assume that data is laid out such that : \n",
    "    # 1. Each embedding is indexed with a group of sparse indices,\n",
    "    #    corresponding to a single lookup\n",
    "    # 2. For each Embedding the lookups are further organized into a batch\n",
    "    # 3. For a list of Embedding tables there is a list of batched lookups\n",
    "    \n",
    "    ly = []\n",
    "    # for k, sparse_index_group_batch in enumerate(lS_i):\n",
    "    for k in range(len(lS_i)):\n",
    "        \n",
    "        sparse_index_group_batch = lS_i[k]\n",
    "        sparse_offset_group_batch = lS_o[k]\n",
    "        \n",
    "        # Offset is simply character location within that file , usually starting with 0:\n",
    "        # thus offset 240 is actually 241st byte in the file\n",
    "        \n",
    "        # Embedding Lookup\n",
    "        # We are using Embedding Bag, which implicitly uses sum operator\n",
    "        # The embeddings are represented as tall matrices, with sum\n",
    "        # happening vertically across 0 axis, resulting in a row vector\n",
    "        E = emb_l[k]\n",
    "        V = E(sparse_index_group_batch, sparse_offset_group_batch)\n",
    "        \n",
    "        ly.append(V)\n",
    "        \n",
    "    # print(ly)\n",
    "    return ly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013192,
     "end_time": "2020-11-22T15:08:20.956155",
     "exception": false,
     "start_time": "2020-11-22T15:08:20.942963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Multi-Layer Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:20.994947Z",
     "iopub.status.busy": "2020-11-22T15:08:20.994306Z",
     "iopub.status.idle": "2020-11-22T15:08:20.997523Z",
     "shell.execute_reply": "2020-11-22T15:08:20.997033Z"
    },
    "papermill": {
     "duration": 0.027963,
     "end_time": "2020-11-22T15:08:20.997637",
     "exception": false,
     "start_time": "2020-11-22T15:08:20.969674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DLRM_Net(nn.Module):\n",
    "    \n",
    "    def create_mlp(self, ln, sigmoid_layer):\n",
    "        \n",
    "        # BUILD MLP layer by layer\n",
    "        layers = nn.ModuleList() # Holding layers as submodules in a list format\n",
    "        \n",
    "        for i in range(0, ln.size - 1):\n",
    "            \n",
    "            n = ln[i]\n",
    "            m = ln[i+1]\n",
    "            \n",
    "            # Construct fully connected operator\n",
    "            LL = nn.Linear(int(n), int(m), bias = True)\n",
    "            \n",
    "            mean = 0.0\n",
    "            std_dev = np.sqrt(2 / (m+n))\n",
    "            W = np.random.normal(mean, std_dev, size = (m, n)).astype(np.float32)\n",
    "            \n",
    "            std_dev = np.sqrt(1/ m)\n",
    "            bt = np.random.normal(mean, std_dev, size = m).astype(np.float32)\n",
    "            \n",
    "            LL.weight.data = torch.tensor(W, requires_grad = True)\n",
    "            LL.bias.data = torch.tensor(bt, requires_grad = True)\n",
    "            \n",
    "            layers.append(LL)\n",
    "            \n",
    "            if i == sigmoid_layer:\n",
    "                \n",
    "                layers.append(LL)\n",
    "                \n",
    "            else:\n",
    "                layers.append(nn.ReLU())\n",
    "                \n",
    "            return torch.nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "    def apply_mlp(self, x, layers):\n",
    "        \n",
    "        # Approach 1 : use ModuleList\n",
    "        # for layer in layers:\n",
    "        #        x = layer(x)\n",
    "        # return x\n",
    "        \n",
    "        # Approach 2 : Use Sequential container to wrap all layers\n",
    "        return layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013206,
     "end_time": "2020-11-22T15:08:21.024514",
     "exception": false,
     "start_time": "2020-11-22T15:08:21.011308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **FACTORIZATION MACHINES**\n",
    "\n",
    "Checking interaction of different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:21.063533Z",
     "iopub.status.busy": "2020-11-22T15:08:21.062704Z",
     "iopub.status.idle": "2020-11-22T15:08:21.065718Z",
     "shell.execute_reply": "2020-11-22T15:08:21.065039Z"
    },
    "papermill": {
     "duration": 0.027152,
     "end_time": "2020-11-22T15:08:21.065838",
     "exception": false,
     "start_time": "2020-11-22T15:08:21.038686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interact_features(self, x, ly):\n",
    "    \n",
    "    if self.arch_interaction_op == \"dot\":\n",
    "        \n",
    "        # Concatenate dense and sparse features\n",
    "        (batch_size, d) = x.shape\n",
    "        T = torch.cat([x] + ly, dim = 1).view(batch_size, -1, d)\n",
    "        \n",
    "        ### Perform a dot product\n",
    "        Z = torch.bmm(T, torch.transpose(T, 1, 2))\n",
    "        \n",
    "        # torch.bmm : Performs a batch matrix-matrix product of matrices\n",
    "        \n",
    "        # Append dense feature with the interaction sinto a row vector\n",
    "        \n",
    "        # Approach 1 : all\n",
    "        # Zflat = Z.view(batch_size, -1)\n",
    "        \n",
    "        # Appraoch 2 : unique\n",
    "        _, ni, nj = Z.shape\n",
    "        \n",
    "         # Approach 1 : tril_indices \n",
    "    # offset = 0 if self.arch_interaction_itself else -1\n",
    "    # li, lj - torch.tril_indices (ni, nj, offset = offset)\n",
    "    \n",
    "        # Approach 2 : Custom \n",
    "        offset = 1 if self.arch_interaction_itself else 0\n",
    "        \n",
    "        li = torch.tensor([i for i in range(ni) for j in range(i+offset)])\n",
    "        lj = torch.tensor([ j for i in range(nj) for j in range(i + offset)])\n",
    "        Zflat = Z[:, li, lj]\n",
    "        \n",
    "        # Concatenate dense features and interactions \n",
    "        R = torch.cat([x] + [ZFlat], dim = 1)\n",
    "        \n",
    "    elif self.arch_interaction_op == \"cat\":\n",
    "        # Concatenate features into a row vector\n",
    "        R = torch.cat([x] + ly, dim = 1)\n",
    "        \n",
    "    else : \n",
    "        sys.exit(\n",
    "        \"ERROR: --arch-interactopn-op=\"\n",
    "        + self.arch_interaction_op\n",
    "        + \" is not supported\"\n",
    "        )\n",
    "        \n",
    "    return R\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013467,
     "end_time": "2020-11-22T15:08:21.093056",
     "exception": false,
     "start_time": "2020-11-22T15:08:21.079589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **SEQUENTIAL AND PARALLEL EXECUTION**\n",
    "\n",
    "Depending on number of devices\n",
    "\n",
    "# # For simplified workflow of events follow sequential execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:21.145752Z",
     "iopub.status.busy": "2020-11-22T15:08:21.144656Z",
     "iopub.status.idle": "2020-11-22T15:08:21.148091Z",
     "shell.execute_reply": "2020-11-22T15:08:21.147542Z"
    },
    "papermill": {
     "duration": 0.041556,
     "end_time": "2020-11-22T15:08:21.148224",
     "exception": false,
     "start_time": "2020-11-22T15:08:21.106668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(self, dense_x, lS_o, lS_i):\n",
    "    \n",
    "    if self.ndevices <= 1:\n",
    "        return self.sequential_forward(dense_x, lS_o, lS_i)\n",
    "    \n",
    "    else :\n",
    "        return self.parallel_forward(dense_x, lS_o, lS_i)\n",
    "    \n",
    "def sequential_forward (self, dense_x, lS_o, lS_i):\n",
    "    \n",
    "    # process dense features ( using bottom mlp), resulting in a row vector\n",
    "    x = self.apply_mlp(dense_x, self.bot_l)\n",
    "    \n",
    "    # process sparse features (using embeddings), resulting in a list of row vectors\n",
    "    ly = self.apply_emb(lS_o, lS_i, self.emb_l)\n",
    "    \n",
    "    z = self.interact_features(x, ly)\n",
    "    \n",
    "    # obtain probability of a click using top mlp\n",
    "    p = self.apply_mlp(z, self.top_l)\n",
    "    \n",
    "    # Clamp output if needed\n",
    "    if 0.0 < self.loss_threshold and self.loss_threshold < 1.0 : \n",
    "        z = torch.clamp(p, min = self.loss_threshold, max = (1.0 - self.loss_threshold))\n",
    "        \n",
    "    else : \n",
    "        z= p\n",
    "        \n",
    "    return z\n",
    "\n",
    "\n",
    "def parallel_forward(self, dense_x, lS_o, lS_i):\n",
    "    ### prepare model (overwrite) ###\n",
    "    # WARNING: # of devices must be >= batch size in parallel_forward call\n",
    "    batch_size = dense_x.size()[0]\n",
    "    ndevices = min(self.ndevices, batch_size, len(self.emb_l))\n",
    "    device_ids = range(ndevices)\n",
    "    # WARNING: must redistribute the model if mini-batch size changes(this is common\n",
    "    # for last mini-batch, when # of elements in the dataset/batch size is not even\n",
    "    if self.parallel_model_batch_size != batch_size:\n",
    "        self.parallel_model_is_not_prepared = True\n",
    "\n",
    "    if self.parallel_model_is_not_prepared or self.sync_dense_params:\n",
    "        # replicate mlp (data parallelism)\n",
    "        self.bot_l_replicas = replicate(self.bot_l, device_ids)\n",
    "        self.top_l_replicas = replicate(self.top_l, device_ids)\n",
    "        self.parallel_model_batch_size = batch_size\n",
    "\n",
    "    if self.parallel_model_is_not_prepared:\n",
    "        # distribute embeddings (model parallelism)\n",
    "        t_list = []\n",
    "        for k, emb in enumerate(self.emb_l):\n",
    "            d = torch.device(\"cuda:\" + str(k % ndevices))\n",
    "            emb.to(d)\n",
    "            t_list.append(emb.to(d))\n",
    "        self.emb_l = nn.ModuleList(t_list)\n",
    "        self.parallel_model_is_not_prepared = False\n",
    "\n",
    "    ### prepare input (overwrite) ###\n",
    "    # scatter dense features (data parallelism)\n",
    "    # print(dense_x.device)\n",
    "    dense_x = scatter(dense_x, device_ids, dim=0)\n",
    "    # distribute sparse features (model parallelism)\n",
    "    if (len(self.emb_l) != len(lS_o)) or (len(self.emb_l) != len(lS_i)):\n",
    "        sys.exit(\"ERROR: corrupted model input detected in parallel_forward call\")\n",
    "\n",
    "    t_list = []\n",
    "    i_list = []\n",
    "    for k, _ in enumerate(self.emb_l):\n",
    "        d = torch.device(\"cuda:\" + str(k % ndevices))\n",
    "        t_list.append(lS_o[k].to(d))\n",
    "        i_list.append(lS_i[k].to(d))\n",
    "    lS_o = t_list\n",
    "    lS_i = i_list\n",
    "\n",
    "    ### compute results in parallel ###\n",
    "    # bottom mlp\n",
    "    # WARNING: Note that the self.bot_l is a list of bottom mlp modules\n",
    "    # that have been replicated across devices, while dense_x is a tuple of dense\n",
    "    # inputs that has been scattered across devices on the first (batch) dimension.\n",
    "    # The output is a list of tensors scattered across devices according to the\n",
    "    # distribution of dense_x.\n",
    "    x = parallel_apply(self.bot_l_replicas, dense_x, None, device_ids)\n",
    "    # debug prints\n",
    "    # print(x)\n",
    "\n",
    "    # embeddings\n",
    "    ly = self.apply_emb(lS_o, lS_i, self.emb_l)\n",
    "    # debug prints\n",
    "    # print(ly)\n",
    "\n",
    "    # butterfly shuffle (implemented inefficiently for now)\n",
    "    # WARNING: Note that at this point we have the result of the embedding lookup\n",
    "    # for the entire batch on each device. We would like to obtain partial results\n",
    "    # corresponding to all embedding lookups, but part of the batch on each device.\n",
    "    # Therefore, matching the distribution of output of bottom mlp, so that both\n",
    "    # could be used for subsequent interactions on each device.\n",
    "    if len(self.emb_l) != len(ly):\n",
    "        sys.exit(\"ERROR: corrupted intermediate result in parallel_forward call\")\n",
    "\n",
    "    t_list = []\n",
    "    for k, _ in enumerate(self.emb_l):\n",
    "        d = torch.device(\"cuda:\" + str(k % ndevices))\n",
    "        y = scatter(ly[k], device_ids, dim=0)\n",
    "        t_list.append(y)\n",
    "    # adjust the list to be ordered per device\n",
    "    ly = list(map(lambda y: list(y), zip(*t_list)))\n",
    "    # debug prints\n",
    "    # print(ly)\n",
    "\n",
    "    # interactions\n",
    "    z = []\n",
    "    for k in range(ndevices):\n",
    "        zk = self.interact_features(x[k], ly[k])\n",
    "        z.append(zk)\n",
    "    # debug prints\n",
    "    # print(z)\n",
    "\n",
    "    # top mlp\n",
    "    # WARNING: Note that the self.top_l is a list of top mlp modules that\n",
    "    # have been replicated across devices, while z is a list of interaction results\n",
    "    # that by construction are scattered across devices on the first (batch) dim.\n",
    "    # The output is a list of tensors scattered across devices according to the\n",
    "    # distribution of z.\n",
    "    p = parallel_apply(self.top_l_replicas, z, None, device_ids)\n",
    "\n",
    "    ### gather the distributed results ###\n",
    "    p0 = gather(p, self.output_d, dim=0)\n",
    "\n",
    "    # clamp output if needed\n",
    "    if 0.0 < self.loss_threshold and self.loss_threshold < 1.0:\n",
    "        z0 = torch.clamp(\n",
    "            p0, min=self.loss_threshold, max=(1.0 - self.loss_threshold)\n",
    "        )\n",
    "    else:\n",
    "        z0 = p0\n",
    "\n",
    "    return z0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013444,
     "end_time": "2020-11-22T15:08:21.175842",
     "exception": false,
     "start_time": "2020-11-22T15:08:21.162398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# # DATA PREPROCESSING : CRITEO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:21.209553Z",
     "iopub.status.busy": "2020-11-22T15:08:21.208587Z",
     "iopub.status.idle": "2020-11-22T15:08:21.213115Z",
     "shell.execute_reply": "2020-11-22T15:08:21.212487Z"
    },
    "papermill": {
     "duration": 0.023649,
     "end_time": "2020-11-22T15:08:21.213250",
     "exception": false,
     "start_time": "2020-11-22T15:08:21.189601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-551895b8c07f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-551895b8c07f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from __future__ import absolute_import, division. print_function, unicode_literals\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division. print_function, unicode_literals\n",
    "\n",
    "# others\n",
    "\n",
    "from os import path\n",
    "import bisect\n",
    "import collections\n",
    "\n",
    "import data_utils\n",
    "\n",
    "# numpy \n",
    "import numpy as np\n",
    "from numpy import random as ra\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, RandomSampler\n",
    "\n",
    "import data_loader_terabyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:21.275074Z",
     "iopub.status.busy": "2020-11-22T15:08:21.251527Z",
     "iopub.status.idle": "2020-11-22T15:08:21.341327Z",
     "shell.execute_reply": "2020-11-22T15:08:21.340676Z"
    },
    "papermill": {
     "duration": 0.113894,
     "end_time": "2020-11-22T15:08:21.341452",
     "exception": false,
     "start_time": "2020-11-22T15:08:21.227558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-afeea968432a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m# uniform ditribution (input data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRandomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     def __init__(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def make_criteo_data_and_loaders(args):\n",
    "\n",
    "\n",
    "  # called from DATA_S_PYTORCH\n",
    "\n",
    "    if args.mlperf_logging and args.memory_map and args.data_set == \"terabyte\":\n",
    "        # more efficient for larger batches\n",
    "        data_directory = path.dirname(args.raw_data_file)\n",
    "\n",
    "        if args.mlperf_bin_loader:\n",
    "            lstr = args.processed_data_file.split(\"/\")\n",
    "            d_path = \"/\".join(lstr[0:-1]) + \"/\" + lstr[-1].split(\".\")[0]\n",
    "            train_file = d_path + \"_train.bin\"\n",
    "            test_file = d_path + \"_test.bin\"\n",
    "            # val_file = d_path + \"_val.bin\"\n",
    "            counts_file = args.raw_data_file + '_fea_count.npz'\n",
    "\n",
    "            if any(not path.exists(p) for p in [train_file,\n",
    "                                                test_file,\n",
    "                                                counts_file]):\n",
    "                ensure_dataset_preprocessed(args, d_path)\n",
    "\n",
    "            train_data = data_loader_terabyte.CriteoBinDataset(\n",
    "                data_file=train_file,\n",
    "                counts_file=counts_file,\n",
    "                batch_size=args.mini_batch_size,\n",
    "                max_ind_range=args.max_ind_range\n",
    "            )\n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                train_data,\n",
    "                batch_size=None,\n",
    "                batch_sampler=None,\n",
    "                shuffle=False,\n",
    "                num_workers=0,\n",
    "                collate_fn=None,\n",
    "                pin_memory=False,\n",
    "                drop_last=False,\n",
    "                sampler=RandomSampler(train_data) if args.mlperf_bin_shuffle else None\n",
    "            )\n",
    "\n",
    "            test_data = data_loader_terabyte.CriteoBinDataset(\n",
    "                data_file=test_file,\n",
    "                counts_file=counts_file,\n",
    "                batch_size=args.test_mini_batch_size,\n",
    "                max_ind_range=args.max_ind_range\n",
    "            )\n",
    "\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                test_data,\n",
    "                batch_size=None,\n",
    "                batch_sampler=None,\n",
    "                shuffle=False,\n",
    "                num_workers=0,\n",
    "                collate_fn=None,\n",
    "                pin_memory=False,\n",
    "                drop_last=False,\n",
    "            )\n",
    "        else:\n",
    "            data_filename = args.raw_data_file.split(\"/\")[-1]\n",
    "\n",
    "            train_data = CriteoDataset(\n",
    "                args.data_set,\n",
    "                args.max_ind_range,\n",
    "                args.data_sub_sample_rate,\n",
    "                args.data_randomize,\n",
    "                \"train\",\n",
    "                args.raw_data_file,\n",
    "                args.processed_data_file,\n",
    "                args.memory_map,\n",
    "                args.dataset_multiprocessing\n",
    "            )\n",
    "\n",
    "            test_data = CriteoDataset(\n",
    "                args.data_set,\n",
    "                args.max_ind_range,\n",
    "                args.data_sub_sample_rate,\n",
    "                args.data_randomize,\n",
    "                \"test\",\n",
    "                args.raw_data_file,\n",
    "                args.processed_data_file,\n",
    "                args.memory_map,\n",
    "                args.dataset_multiprocessing\n",
    "            )\n",
    "\n",
    "            train_loader = data_loader_terabyte.DataLoader(\n",
    "                data_directory=data_directory,\n",
    "                data_filename=data_filename,\n",
    "                days=list(range(23)),\n",
    "                batch_size=args.mini_batch_size,\n",
    "                max_ind_range=args.max_ind_range,\n",
    "                split=\"train\"\n",
    "            )\n",
    "\n",
    "            test_loader = data_loader_terabyte.DataLoader(\n",
    "                data_directory=data_directory,\n",
    "                data_filename=data_filename,\n",
    "                days=[23],\n",
    "                batch_size=args.test_mini_batch_size,\n",
    "                max_ind_range=args.max_ind_range,\n",
    "                split=\"test\"\n",
    "            )\n",
    "    else:\n",
    "        train_data = CriteoDataset(\n",
    "            args.data_set,\n",
    "            args.max_ind_range,\n",
    "            args.data_sub_sample_rate,\n",
    "            args.data_randomize,\n",
    "            \"train\",\n",
    "            args.raw_data_file,\n",
    "            args.processed_data_file,\n",
    "            args.memory_map,\n",
    "            args.dataset_multiprocessing\n",
    "        )\n",
    "\n",
    "        test_data = CriteoDataset(\n",
    "            args.data_set,\n",
    "            args.max_ind_range,\n",
    "            args.data_sub_sample_rate,\n",
    "            args.data_randomize,\n",
    "            \"test\",\n",
    "            args.raw_data_file,\n",
    "            args.processed_data_file,\n",
    "            args.memory_map,\n",
    "            args.dataset_multiprocessing\n",
    "        )\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_data,\n",
    "            batch_size=args.mini_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=args.num_workers,\n",
    "            collate_fn=collate_wrapper_criteo,\n",
    "            pin_memory=False,\n",
    "            drop_last=False,  # True\n",
    "        )\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_data,\n",
    "            batch_size=args.test_mini_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=args.test_num_workers,\n",
    "            collate_fn=collate_wrapper_criteo,\n",
    "            pin_memory=False,\n",
    "            drop_last=False,  # True\n",
    "        )\n",
    "\n",
    "    return train_data, train_loader, test_data, test_loader\n",
    "\n",
    "\n",
    "# uniform ditribution (input data)\n",
    "class RandomDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            m_den,\n",
    "            ln_emb,\n",
    "            data_size,\n",
    "            num_batches,\n",
    "            mini_batch_size,\n",
    "            num_indices_per_lookup,\n",
    "            num_indices_per_lookup_fixed,\n",
    "            num_targets=1,\n",
    "            round_targets=False,\n",
    "            data_generation=\"random\",\n",
    "            trace_file=\"\",\n",
    "            enable_padding=False,\n",
    "            reset_seed_on_access=False,\n",
    "            rand_seed=0\n",
    "    ):\n",
    "        # compute batch size\n",
    "        nbatches = int(np.ceil((data_size * 1.0) / mini_batch_size))\n",
    "        if num_batches != 0:\n",
    "            nbatches = num_batches\n",
    "            data_size = nbatches * mini_batch_size\n",
    "            # print(\"Total number of batches %d\" % nbatches)\n",
    "\n",
    "        # save args (recompute data_size if needed)\n",
    "        self.m_den = m_den\n",
    "        self.ln_emb = ln_emb\n",
    "        self.data_size = data_size\n",
    "        self.num_batches = nbatches\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.num_indices_per_lookup = num_indices_per_lookup\n",
    "        self.num_indices_per_lookup_fixed = num_indices_per_lookup_fixed\n",
    "        self.num_targets = num_targets\n",
    "        self.round_targets = round_targets\n",
    "        self.data_generation = data_generation\n",
    "        self.trace_file = trace_file\n",
    "        self.enable_padding = enable_padding\n",
    "        self.reset_seed_on_access = reset_seed_on_access\n",
    "        self.rand_seed = rand_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T15:08:21.390614Z",
     "iopub.status.busy": "2020-11-22T15:08:21.385527Z",
     "iopub.status.idle": "2020-11-22T15:08:21.394859Z",
     "shell.execute_reply": "2020-11-22T15:08:21.394221Z"
    },
    "papermill": {
     "duration": 0.038283,
     "end_time": "2020-11-22T15:08:21.394975",
     "exception": false,
     "start_time": "2020-11-22T15:08:21.356692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-17784370b964>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-17784370b964>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Kaggle Display Advertising Challenge Dataset\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Kaggle Display Advertising Challenge Dataset\n",
    "# dataset (str): name of dataset (Kaggle or Terabyte)\n",
    "# randomize (str): determines randomization scheme\n",
    "#            \"none\": no randomization\n",
    "#            \"day\": randomizes each day\"s data (only works if split = True)\n",
    "#            \"total\": randomizes total dataset\n",
    "# split (bool) : to split into train, test, validation data-sets\n",
    "class CriteoDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset,\n",
    "            max_ind_range,\n",
    "            sub_sample_rate,\n",
    "            randomize,\n",
    "            split=\"train\",\n",
    "            raw_path=\"\",\n",
    "            pro_data=\"\",\n",
    "            memory_map=False,\n",
    "            dataset_multiprocessing=False\n",
    "    ):\n",
    "        # dataset\n",
    "        # tar_fea = 1   # single target\n",
    "        den_fea = 13  # 13 dense  features\n",
    "        # spa_fea = 26  # 26 sparse features\n",
    "        # tad_fea = tar_fea + den_fea\n",
    "        # tot_fea = tad_fea + spa_fea\n",
    "        if dataset == \"kaggle\":\n",
    "            days = 7\n",
    "            out_file = \"kaggleAdDisplayChallenge_processed\"\n",
    "        elif dataset == \"terabyte\":\n",
    "            days = 24\n",
    "            out_file = \"terabyte_processed\"\n",
    "        else:\n",
    "            raise(ValueError(\"Data set option is not supported\"))\n",
    "        self.max_ind_range = max_ind_range\n",
    "        self.memory_map = memory_map\n",
    "\n",
    "        # split the datafile into path and filename\n",
    "        lstr = raw_path.split(\"/\")            # Splitting dataset into file\n",
    "        self.d_path = \"/\".join(lstr[0:-1]) + \"/\"    \n",
    "        self.d_file = lstr[-1].split(\".\")[0] if dataset == \"kaggle\" else lstr[-1]\n",
    "        self.npzfile = self.d_path + (\n",
    "            (self.d_file + \"_day\") if dataset == \"kaggle\" else self.d_file\n",
    "        )  # Creating npz file \n",
    "        self.trafile = self.d_path + (\n",
    "            (self.d_file + \"_fea\") if dataset == \"kaggle\" else \"fea\"\n",
    "        )\n",
    "\n",
    "        # check if pre-processed data is available\n",
    "        data_ready = True\n",
    "        if memory_map:\n",
    "\n",
    "          # memory_map : Takes input from user while executing data_s_pytorch\n",
    "            for i in range(days):\n",
    "                reo_data = self.npzfile + \"_{0}_reordered.npz\".format(i)\n",
    "                \n",
    "                if not path.exists(str(reo_data)):\n",
    "                    data_ready = False\n",
    "        else:\n",
    "            if not path.exists(str(pro_data)):\n",
    "                data_ready = False\n",
    "\n",
    "        # pre-process data if needed\n",
    "        # WARNNING: when memory mapping is used we get a collection of files\n",
    "\n",
    "        if data_ready:\n",
    "            print(\"Reading pre-processed data=%s\" % (str(pro_data)))\n",
    "            file = str(pro_data)\n",
    "\n",
    "        else:\n",
    "            print(\"Reading raw data=%s\" % (str(raw_path)))\n",
    "            file = data_utils.getCriteoAdData(\n",
    "                raw_path,\n",
    "                out_file,\n",
    "                max_ind_range,\n",
    "                sub_sample_rate,\n",
    "                days,\n",
    "                split,\n",
    "                randomize,\n",
    "                dataset == \"kaggle\",\n",
    "                memory_map,\n",
    "                dataset_multiprocessing\n",
    "            )\n",
    "\n",
    "        # get a number of samples per day\n",
    "        total_file = self.d_path + self.d_file + \"_day_count.npz\"\n",
    "        with np.load(total_file) as data:\n",
    "            total_per_file = data[\"total_per_file\"]\n",
    "\n",
    "\n",
    "        # Taken from Google :::::\n",
    "        # An offset into a file is simply the character location within that file, \n",
    "        # usually starting with 0; thus \"offset 240\" is actually the 241st byte in the file.\n",
    "        # compute offsets per file\n",
    "\n",
    "        self.offset_per_file = np.array([0] + [x for x in total_per_file])\n",
    "\n",
    "        for i in range(days):\n",
    "            self.offset_per_file[i + 1] += self.offset_per_file[i]\n",
    "\n",
    "        # print(self.offset_per_file)\n",
    "\n",
    "        # setup data\n",
    "        if memory_map:\n",
    "            # setup the training/testing split\n",
    "            self.split = split\n",
    "            if split == 'none' or split == 'train':\n",
    "                self.day = 0\n",
    "                self.max_day_range = days if split == 'none' else days - 1\n",
    "            elif split == 'test' or split == 'val':\n",
    "                self.day = days - 1\n",
    "                num_samples = self.offset_per_file[days] - \\\n",
    "                              self.offset_per_file[days - 1]\n",
    "                self.test_size = int(np.ceil(num_samples / 2.))\n",
    "                self.val_size = num_samples - self.test_size\n",
    "            else:\n",
    "                sys.exit(\"ERROR: dataset split is neither none, nor train or test.\")\n",
    "                \n",
    "                 # dense feature\n",
    "                lX.append(Xt)\n",
    "                # sparse feature (sparse indices)\n",
    "                lS_offsets.append(lS_emb_offsets)\n",
    "                lS_indices.append(lS_emb_indices)\n",
    "\n",
    "                # generate a batch of target (probability of a click)\n",
    "                P = generate_random_output_batch(n, num_targets, round_targets)\n",
    "                lT.append(P)\n",
    "\n",
    "            return (nbatches, lX, lS_offsets, lS_indices, lT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 7.400071,
   "end_time": "2020-11-22T15:08:21.521521",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-22T15:08:14.121450",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
